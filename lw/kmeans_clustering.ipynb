{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering on Iris Dataset\n",
    "**Author:** Magudeshwaran and Senthilkumaran\n",
    "\n",
    "**Goal:** Group similar iris flowers into clusters using the K-Means algorithm, after reducing data dimensions with PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries\n",
    "We need `pandas` for data, `numpy` for numbers, `matplotlib` for plotting, and `sklearn` for scaling, PCA, and K-Means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "\n",
    "# Fix for potential threadpoolctl error\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the Data\n",
    "We load the Iris dataset, a classic for clustering. It contains measurements of different iris flower species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Prepare the Data\n",
    "We prepare our data by:\n",
    "- Selecting only the numerical features for clustering.\n",
    "- Scaling the features so they all have a similar range.\n",
    "- Using PCA to reduce the data to 2 dimensions for easy plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical features\n",
    "X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].values\n",
    "y_true = df['species'].values # True labels for comparison, not used in clustering\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA to reduce to 2 components for visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Determine Optimal K (Elbow Method)\n",
    "The Elbow Method helps us find the best number of clusters (K). We plot the \"inertia\" (sum of squared distances of samples to their closest cluster center) for different K values. The \"elbow point\" in the plot suggests an optimal K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "K = range(1, 11)\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10) # Set n_init explicitly\n",
    "    kmeans.fit(X_pca)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K, inertia, 'bx-')\n",
    "plt.xlabel('Number of clusters (K)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method For Optimal K')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Apply K-Means with Optimal K\n",
    "From the elbow plot, K=3 seems to be a good choice. Now we apply K-Means with 3 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10) # Set n_init explicitly\n",
    "clusters = kmeans.fit_predict(X_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Visualize the Clusters\n",
    "Finally, we plot the clustered data. We can see how K-Means has grouped the data points into three distinct clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis', marker='o', s=50, edgecolor='k')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.75, marker='X') # Plot cluster centers\n",
    "plt.title('K-Means Clustering of Iris Data (PCA-reduced)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.colorbar(label='Cluster Label')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
