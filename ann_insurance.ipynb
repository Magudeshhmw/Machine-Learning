{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN to Predict Insurance Purchase\n",
    "**Author:** Magudeshwaran and Senthilkumaran\n",
    "\n",
    "**Goal:** Predict whether a person will buy insurance based on their age using an Artificial Neural Network (ANN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries\n",
    "We will import the tools we need.\n",
    "- `pandas`: To load and work with data.\n",
    "- `sklearn`: For splitting and scaling our data.\n",
    "- `tensorflow.keras`: To build our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the Data\n",
    "Here, we load the insurance dataset from a URL and look at the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/codebasics/deep-learning-keras-tf-tutorial/master/1_neuron/insurance_data.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Split the Data\n",
    "We split our data into training and testing sets.\n",
    "- **Feature (X):** `age`\n",
    "- **Target (y):** `bought_insurance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['age']]\n",
    "y = df['bought_insurance']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Scale the Data\n",
    "We scale our `age` feature to be between 0 and 1. This helps the neural network learn more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Build the Neural Network\n",
    "We will create a simple neural network with three layers:\n",
    "1. An **Input Layer**.\n",
    "2. A **Hidden Layer** with 10 neurons and a `relu` activation function.\n",
    "3. An **Output Layer** with 1 neuron and a `sigmoid` activation function (to output a probability between 0 and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([
",
    "    Input(shape=(1,)),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Compile the Model\n",
    "Before training, we need to configure the model with an optimizer, a loss function, and metrics.\n",
    "- **Optimizer:** `adam` is an efficient optimizer.\n",
    "- **Loss Function:** `binary_crossentropy` is used for binary (0 or 1) classification problems.\n",
    "- **Metrics:** We will monitor the `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the Model\n",
    "Now we train the model on our scaled training data for 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate the Model\n",
    "Let's see how well our model performs on the unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f"Accuracy on test set: {accuracy * 100:.2f}%")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Make Predictions\n",
    "Finally, we can use our trained model to make predictions on the test data. The output will be 0 (will not buy) or 1 (will buy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
    "print(\"Predictions on test data:\")\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}